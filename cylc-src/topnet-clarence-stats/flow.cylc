#!jinja2
{% set NTHREADS = 1, 2, 2 %}
{% set HINT = "multithread", "multithread", "nomultithread" %}
{% set N = NTHREADS | length %}
# number of runs
{% set M = 5 %}
{% set toolchain_name = '4.6.0-iimpi-2022a' %}
{% set fc = 'ifort' %}
{% set topnet_src = '/nesi/nobackup/pletzera/topnet-code/topnet-merge_TOP-83_Evap_with_ETI_Snow-GW_ap_io/' %}
{% set build_dir = '/nesi/nobackup/pletzera/topnet_runs/topnet-clarence-stats' %}
{% set input_dir = '/nesi/nobackup/pletzera/topnet_2024/runs/Clarence/input_data' %}

[scheduling]
  [[graph]]
    R1 = """
{% for I in range(N) %}
   {% for J in range(M) %}
     build => run{{ NTHREADS[I] }}threads_{{ HINT[I] }}_{{ J }} => analyse
   {% endfor %}
{% endfor %}
  """

[runtime]

  [[build]]
    script = """
      mkdir -p {{ build_dir }}
      cd {{ build_dir }}
      bdir={{ toolchain_name }}
      #rm -rf $bdir
      #mkdir -p $bdir
      #cd $bdir
      #module purge
      #module load CMake
      #module load netCDF-Fortran/{{ toolchain_name }}
      #FC={{ fc }} cmake {{ topnet_src }}
      #make clean
      #make
    """

{% for I in range(N) %}
    {% for J in range(M) %}

  [[run{{ NTHREADS[I] }}threads_{{ HINT[I] }}_{{ J }}]]
    platform = mahuika-slurm
    script = """

bdir={{ build_dir }}/{{ toolchain_name }}
cd $bdir
echo "now in $bdir"

sdir1="{{ NTHREADS[I] }}threads"
sdir2="{{ HINT[I] }}"
sdir3="{{ J }}"

rm -rf run/${sdir1}_${sdir2}/$sdir3
mkdir -p run/${sdir1}_${sdir2}/$sdir3
cd run/${sdir1}_${sdir2}/$sdir3
echo "now in $PWD"

cp {{ input_dir }}/io_paths.nml .
cp {{ input_dir }}/topnet_info_13000000-CL_2000.nml .
ls

mkdir output restart
module purge
module load netCDF-Fortran/{{ toolchain_name }}
$bdir/source/topnet topnet_info_13000000-CL_2000.nml >& topnet-out.txt
    """
    [[[directives]]]
      --time = 01:00:00
      --mem = 5g
      --cpus-per-task = {{ NTHREADS[I] }}
      --hint = {{ HINT[I] }}
{% if toolchain_name != '4.4.4-intel-2017a' %}
      --partition = milan
{% endif %}

   {% endfor %}
{% endfor %}

  [[analyse]]
    platform = localhost
    script = """

        cd {{ build_dir }}/{{ toolchain_name }}/run

	# generate execution time table
        ranstr=$(echo $RANDOM | md5sum | head -c 20)
        tablename="table-${ranstr}.txt"
        sqlite3 $CYLC_WORKFLOW_RUN_DIR/log/db "select job_id, cycle, name, submit_num, time_run, time_run_exit from task_jobs;" > $tablename
        cat $tablename

        # create csv file
        cat > "table-${ranstr}.py" << EOF
import pandas as pd
data = pd.read_csv("table-${ranstr}.txt", sep="|")
# add column names
data.columns = ['jobid', 'run', 'task', 'step', 'start', 'end']
dt = pd.to_datetime(data.end) - pd.to_datetime(data.start)
data['exec_time_sec'] = dt.astype('timedelta64[s]').values
print(data)
data.to_csv("table-${ranstr}.csv")
EOF
        module purge
        module load Python
        python "table-${ranstr}.py"
    """
